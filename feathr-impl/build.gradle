plugins {
  id 'scala'
  id 'com.github.johnrengelman.shadow' version '7.1.2'
}

configurations {
  // Dependencies that will be provided at runtime in the cloud execution
  provided

  compileOnly.extendsFrom(provided)
  testImplementation.extendsFrom provided
}

configurations.all {
  resolutionStrategy.force "org.antlr:antlr4-runtime:4.8"
  resolutionStrategy.force "org.antlr:antlr4-tool:4.8"
}

dependencies {
  implementation project(":feathr-compute")
  implementation project(":feathr-config")
  implementation project(":feathr-data-models")
  implementation project(path: ':feathr-data-models', configuration: 'dataTemplate')
  implementation spec.product.scala.scala_library

  implementation spec.product.jackson.dataformat_csv
  implementation spec.product.jackson.dataformat_yaml
  implementation spec.product.jackson.module_scala
  implementation spec.product.jackson.dataformat_hocon
  implementation spec.product.spark_redis
  implementation spec.product.fastutil
  implementation spec.product.hadoop.mapreduce_client_core
  implementation spec.product.mvel
  implementation spec.product.jackson.jackson_module_caseclass
  implementation spec.product.protobuf
  implementation spec.product.guava
  implementation spec.product.xbean
  implementation spec.product.json

  provided spec.product.jackson.jackson_databind
  provided spec.product.typesafe_config
  provided spec.product.log4j
  provided spec.product.hadoop.common
  provided(spec.product.spark.spark_core) {
    exclude group: 'org.apache.xbean', module: 'xbean-asm6-shaded'
  }
  provided(spec.product.spark.spark_avro) {
    exclude group: 'org.apache.xbean', module: 'xbean-asm6-shaded'
  }
  provided(spec.product.spark.spark_hive) {
    exclude group: 'com.tdunning', module: 'json'
  }
  provided spec.product.spark.spark_sql

  testImplementation spec.product.equalsverifier
  testImplementation spec.product.spark.spark_catalyst
  testImplementation spec.product.mockito
  testImplementation spec.product.scala.scalatest
  testImplementation spec.product.testing
  testImplementation spec.product.jdiagnostics
  testImplementation spec.product.antlr
  testImplementation spec.product.antlrRuntime
}

// Since there are cross-calls from Scala to Java, we use joint compiler
// to compile them at the same time with Scala compiler.
// See https://docs.gradle.org/current/userguide/scala_plugin.html
sourceSets {
  main {
    scala {
      srcDirs = ['src/main/scala', 'src/main/java']
    }
    java {
      srcDirs = []
    }
  }
  test {
    scala {
      srcDirs = ['src/test/scala', 'src/test/java']
    }
    java {
      srcDirs = []
    }
  }
}

ext {
  fatJarConfig = [
      "local": [
          "classPath"  : [project.configurations.runtimeClasspath, project.configurations.provided],
          "mainClass"  : "com.linkedin.feathr.cli.FeatureExperimentEntryPoint",
          "description": "Build jar for local experimentation"
      ],
      "cloud": [
          "classPath"  : [project.configurations.runtimeClasspath],
          "mainClass"  : "com.linkedin.feathr.offline.job.FeatureJoinJob",
          "description": "Build jar for running Feathr in the cloud"
      ]
  ]
}

fatJarConfig.each { kind, entry ->
  tasks.register("${kind}Jar", com.github.jengelman.gradle.plugins.shadow.tasks.ShadowJar) {
    description entry.description
    archiveClassifier.set(kind)

    with jar
    manifest {
      attributes "Main-Class": entry.mainClass
    }
    configurations = entry.classPath

    exclude 'META-INF/*.DSA'
    exclude 'META-INF/*.SF'

    mergeServiceFiles()

    zip64 true

    // Some systems(like Hadoop) use different versinos of protobuf(like v2) so we have to shade it.
    relocate ('com.google.protobuf', 'shade.com.google.protobuf')
  }
}

test {
  useTestNG()
}
